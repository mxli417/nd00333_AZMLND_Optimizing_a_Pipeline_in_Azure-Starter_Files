# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Useful Resources
- [ScriptRunConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrunconfig?view=azure-ml-py)
- [Configure and submit training runs](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-set-up-training-targets)
- [HyperDriveConfig Class](https://docs.microsoft.com/en-us/python/api/azureml-train-core/azureml.train.hyperdrive.hyperdriveconfig?view=azure-ml-py)
- [How to tune hyperparamters](https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters)


## Summary
- in this project, we are looking at the [UCI bank marketing dataset](https://archive.ics.uci.edu/ml/datasets/bank+marketing), trying to predict if the client will subscribe to a term deposit
- we try two approaches: manually guided Azure Hyperdrive sklearn - hyperparameter optimization vs. an Azure AutoML approach
- the best performing model was the xxxx

## Scikit-learn Pipeline

**Pipeline Architecture**

- the pipeline progresses step-by-step across:
    - **data preparation**
        - dataset retrieval from    a  given URL with the use of the TabularDataSetFactory
        - data cleaning (creation of dummy values for categorical variables, cleaning dates, etc. )
        - dataset splitting (75:25) for training and testing
    - **model definition**
        - definition of the main LogisticRegression classificator
        - parameterization of the fitting method of the classifier by the two hyperparameters `max_iter` and the regularization parameter `C`
    - **hyper drive preparation**
        - defining an Sklearn estimator for use in the hyperdrive hyperparameter optimization runs
        - definition of the hyperdrive config, setting the sampling methods (`RandomSampling`) for the defined hyperparameters as well as the early stopping policy (`BanditPolicy`)
    - **hyperparameter optimization with hyperdrive**
        - execution on a compute cluster with the hyper drive configs 
        - selecting the best performing Logistic Regression classifier with an accuracy of ~91 percent for the given prediction problem
        - serialization of the best model

**Parameter sampler choice**

- the chose parameter sampler is used to sample from the pre-defined search spaces on the main hyperparameters `C` (for regularization) and `max_iters` (the maximum number of solver iterations to converge)

- the random parameter sampler helps progressing easily through the hyperparamter search space bc. of its non-exhaustive nature, sampling suitable hyperparameters randomly

**Early stopping policy**

- Setting an Early stopping policy on hyperparameter optimization experiments comes with two main advantages: 
    - computations are stopped if there is no more improvement in model accuracy
    - the amount of expended computation resources is limited by stopping after no more improvements can be made 

- in this pipeline a Bandit Policy is defined for early stopping
    - the slack factor determines how much allowed distance from the best run is tolerated for another model training run
    - the evaluation interval determines the frequency of applying the policy during the hyperparameter optimization



## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
- custom dataset balancing capabilities might be interesting, especially in the area of highly unbalanced datasets like the one given
- custom cost-sensitive metrics might also be interesting for the problem, helping the model to adapt to avoid costly misclassifications

## Proof of cluster clean up
- here is the screenshot of cluster deletion

**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
